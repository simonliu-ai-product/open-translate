# -*- coding: utf-8 -*-
"""[TranslateGemma]Example.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/LiuYuWei/TranslateGemma_example/blob/main/Colab/TranslateGemma_zh_TW_Example.ipynb
"""

#@title Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""## 關於作者

Simon Liu

APMIC MLOps工程師 x Google人工智慧開發者專家 (GDE)

一位人工智慧解決方案領域的技術愛好者，專注於協助企業實施生成式人工智慧 (GAI)、MLOps和大型語言模型 (LLM) 技術，以推動數位轉型和實際技術應用。

目前，他也是GoogleGenAI領域的開發者專家 (GDE)，積極參與技術社區，透過技術文章、演講和實踐經驗分享，推動人工智慧技術的應用和發展。迄今為止，他已在Medium等平台發表了百餘篇技術文章，涵蓋生成式人工智慧、RAG和AI代理等主題，並在許多技術研討會上擔任演講嘉賓，分享人工智慧和生成式人工智慧的實際應用。

相關連結：

- APMIC官方網址：https://www.apmic.ai/
- 個人社群媒體連結：https://simonliuyuwei.my.canva.site/link-in-bio

# TranslateGemma

[TranslateGemma](https://huggingface.co/collections/google/translategemma) 是 Google 推出的一系列輕量級、先進的開源翻譯模型，基於 Gemma 3 模型系列。

TranslateGemma 模型旨在處理 55 種語言的翻譯任務。它們體積相對較小，因此可以部署在資源有限的環境中，例如筆記型電腦、桌上型電腦或您自己的雲端基礎設施，從而使每個人都能平等地使用先進的翻譯模型，並有助於促進創新。

在本 Colab 中，我們將提供一些模型使用範例，幫助您快速上手。

## 導入必要的函式庫
"""

from transformers import pipeline
import torch
from IPython.display import Markdown
import PIL                              # For displaying images
import requests                         # For downloading data
from IPython.display import Javascript  # For setting the height of the picture cell

"""### 將您的 HuggingFace Secret Token 新增至 Colab Secrets（如有必要）

1. 開啟您的 Google Colab 筆記本，然後點擊左側面板中的「Secrets」標籤。

<img src="https://storage.googleapis.com/generativeai-downloads/images/secrets.jpg" alt="您可以在左側面板中找到 Secrets 標籤。" width=50%>

2. 建立一個名為 `HF_TOKEN` 的新 Secret。

3. 將您的 HuggingFace 令牌複製並貼上到 `HF_TOKEN` 的 `Value` 輸入框中。

4. 切換左側的按鈕，讓所有筆記本都能存取此 Secret。
"""

from google.colab import userdata
HF_TOKEN=userdata.get("HF_TOKEN")

"""### 建立管道

為了讓 T4GPU 可以使用，我們將載入最小的模型（4B）。更大模型的使用方法類似。
"""

# 需要花費數分鐘下載 Model 檔案。

pipe = pipeline(
    "image-text-to-text",
    model="google/translategemma-4b-it",
    device="cuda",
    dtype=torch.bfloat16,
    token=HF_TOKEN,
)

"""### 文字翻譯

TranslateGemma 旨在與特定的聊天模板配合使用，支援直接翻譯文字輸入（圖像翻譯請參見下文）。此聊天模板基於 Hugging Face Transformers 的聊天模板系統實現，並與 Gemma 分詞器和 Gemma 3 處理器提供的 apply_chat_template() 函數相容。與其他模型的聊天模板相比，其顯著差異包括：

TranslateGemma 僅支援使用者和助手角色。

* TranslateGemma 的使用者角色有明確的規範：
* content 屬性必須以清單形式提供，且只能包含一個條目。
* content 清單條目必須包含：
  * type 屬性，其值為「text」。
  * 一個字串類型的「source_lang_code」屬性
  * 一個字串類型的「target_lang_code」屬性
  * 一個僅包含待翻譯文字的「text」屬性
* “source_lang_code”和“target_lang_code”屬性值可以採用以下兩種形式之一：
  * ISO 639-1 Alpha-2 語言代碼，例如 `en`；或
  * 區域化變體，即 ISO 639-1 Alpha-2 語言代碼和 ISO 3166-1 Alpha-2 國家/地區代碼對，兩者之間以短橫線或下劃線分隔，例如 `en_US` 或 `en-GB`，類似於 Unicode 通用區域設定資料儲存庫格式。
* 如果模型不支援「source_lang_code」和「target_lang_code」屬性值，則套用範本時會引發錯誤。
"""

text = r"""
Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, “and what is the use of a book,” thought Alice “without pictures or conversations?”

So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.
"""

messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "text",
                "source_lang_code": "en",
                "target_lang_code": "zh-TW",
                "text": text,
            }
        ],
    }
]

output = pipe(text=messages, max_new_tokens=200, generate_kwargs={"do_sample": False})

"""We display the source and the translation using markdown."""

display(Markdown(rf"""
### Source Text:

{text}


###Translation:

{output[0]["generated_text"][-1]["content"]}"""))

"""### 圖片翻譯

圖像翻譯遵循與文字翻譯非常相似的模式，差異在於 `type` 欄位設定為 `image`，並且指定了 `url` 而不是 `text`。

請注意，因為圖片沒有辦法直接從英文轉換成繁體中文，因此我們這邊會使用 opencc 去做字詞翻譯。
"""

!pip install -q opencc

image_url = "https://raw.githubusercontent.com/esalesky/vistra-benchmark/refs/heads/main/images/f488c322.png"

messages = [
  {
      "role": "user",
      "content": [
          {
              "type": "image",
              "source_lang_code": "en",
              "target_lang_code": "zh-TW",
              "url": image_url,
          },
      ],
  }
]
output = pipe(text=messages, max_new_tokens=100, generate_kwargs={"do_sample": False})

# 圖片翻譯的輸出結果如果出現簡體中文是正常的，因為資料集沒有英文轉繁體中文的資料。

image_text = output[0]["generated_text"][-1]["content"]
image_text

import opencc

# 建立轉換器
# 's2t'  = Simplified to Traditional (簡體到繁體，字對字)
# 's2tw' = Simplified to Traditional (Taiwan) (簡體到台灣正體)
# 's2twp' = Simplified to Traditional (Taiwan) with Phrases (簡體到台灣正體 + 詞彙轉換)

converter = opencc.OpenCC('s2twp')
output_text = converter.convert(image_text)

print(output_text)

"""We show the image and the corresponding translation."""

display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))

image = PIL.Image.open(requests.get(image_url, stream=True).raw)
display(Markdown("###Source image:"))
display(image)
display(Markdown(rf"""
### Translation:
{output_text}
"""))